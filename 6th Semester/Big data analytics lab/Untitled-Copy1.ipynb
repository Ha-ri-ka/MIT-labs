{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "spark = SparkSession.builder.appName('recommender').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   4.0|1225734739|\n",
      "|     1|    110|   4.0|1225865086|\n",
      "+------+-------+------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.option(\"inferSchema\", True).option(\"header\", True).csv(\"ratings.csv\").limit(1000)\n",
    "ratings.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(ratings)\n",
    "    for column in [\"userId\", \"movieId\"]\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "ratings_indexed = pipeline.fit(ratings).transform(ratings)\n",
    "\n",
    "training_data,validation_data = ratings_indexed.randomSplit([8.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"userId_index\",itemCol=\"movieId_index\",ratingCol=\"rating\",rank=5,maxIter=3,regParam=0.01,coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = als.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+------------+-------------+-----------+\n",
      "|userId|movieId|rating|timestamp |userId_index|movieId_index|prediction |\n",
      "+------+-------+------+----------+------------+-------------+-----------+\n",
      "|4     |5995   |5.0   |1442455622|12.0        |176.0        |3.380457   |\n",
      "|4     |50872  |5.0   |1442455546|12.0        |70.0         |2.9350915  |\n",
      "|4     |79091  |5.0   |1442456126|12.0        |187.0        |3.382306   |\n",
      "|4     |109487 |4.5   |1442684878|12.0        |86.0         |-0.7537474 |\n",
      "|7     |3      |3.0   |974517393 |1.0         |138.0        |-0.62056565|\n",
      "|7     |62     |3.0   |974519061 |1.0         |78.0         |-1.5140789 |\n",
      "|7     |296    |3.0   |974518074 |1.0         |3.0          |1.7705758  |\n",
      "|7     |349    |4.0   |974520676 |1.0         |58.0         |1.5281651  |\n",
      "|7     |527    |4.0   |974517903 |1.0         |27.0         |-0.49645248|\n",
      "|7     |585    |3.0   |974520261 |1.0         |71.0         |2.2342389  |\n",
      "+------+-------+------+----------+------------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "\n",
    "model = als.fit(training_data)\n",
    "predictions=model.transform(validation_data)\n",
    "predictions.show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 3.9951741883579195\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = spark.read.option(\"inferSchema\", True).option(\"header\", True).csv(\"ratings.csv\").limit(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+--------------+------------+\n",
      "|userId|movieId|rating| timestamp|average_rating|rating_count|\n",
      "+------+-------+------+----------+--------------+------------+\n",
      "|     1|      1|   4.0|1225734739|           4.0|           1|\n",
      "|     1|    110|   4.0|1225865086|           4.0|           1|\n",
      "|     1|    158|   4.0|1225733503|           4.0|           1|\n",
      "|     1|    260|   4.5|1225735204|           4.5|           1|\n",
      "|     1|    356|   5.0|1225735119|           5.0|           1|\n",
      "+------+-------+------+----------+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "# Group by userId and movieId, aggregate ratings\n",
    "aggregated_ratings = ratings.groupBy(\"userId\", \"movieId\") \\\n",
    "    .agg(avg(\"rating\").alias(\"average_rating\"), count(\"rating\").alias(\"rating_count\"))\n",
    "\n",
    "# Join aggregated data back to original DataFrame\n",
    "merged_ratings = ratings.join(aggregated_ratings, [\"userId\", \"movieId\"], \"left_outer\")\n",
    "\n",
    "# Show the merged DataFrame\n",
    "merged_ratings.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(ratings)\n",
    "    for column in [\"userId\", \"movieId\"]\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "ratings_indexed = pipeline.fit(ratings).transform(ratings)\n",
    "\n",
    "training_data,validation_data = ratings_indexed.randomSplit([8.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+------------+-------------+-----------+\n",
      "|userId|movieId|rating|timestamp |userId_index|movieId_index|prediction |\n",
      "+------+-------+------+----------+------------+-------------+-----------+\n",
      "|4     |1097   |3.5   |1442455733|12.0        |15.0         |-0.89528036|\n",
      "|4     |2858   |4.0   |1442455646|12.0        |18.0         |5.629303   |\n",
      "|4     |50872  |5.0   |1442455546|12.0        |70.0         |2.6496496  |\n",
      "|7     |34     |3.0   |974523039 |1.0         |20.0         |-1.2591667 |\n",
      "|7     |39     |2.0   |974519479 |1.0         |64.0         |-0.90530145|\n",
      "|7     |225    |4.0   |974521503 |1.0         |51.0         |0.18725494 |\n",
      "|7     |349    |4.0   |974520676 |1.0         |58.0         |-1.2070689 |\n",
      "|7     |551    |3.0   |974517144 |1.0         |29.0         |-3.589035  |\n",
      "|7     |1246   |4.0   |974522217 |1.0         |96.0         |1.193851   |\n",
      "|7     |1721   |4.0   |974519617 |1.0         |117.0        |-0.61102957|\n",
      "+------+-------+------+----------+------------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "\n",
    "model = als.fit(training_data)\n",
    "predictions=model.transform(validation_data)\n",
    "predictions.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 4.317241908222907\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
