{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### BELOW CODE IS TO WORK WITH SPARK IN COLAB, IGNORE IF NOT USING COLAB"
      ],
      "metadata": {
        "id": "ZrDSRG_k8TnQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHdTWrdh8OkR",
        "outputId": "2d073f7a-0e6e-43a5-902a-a7bf2b7cbbd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 0 B/110 kB 0%] [Connected to cloud.r-project.org (108.157.173.\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,691 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,135 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,974 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,176 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Fetched 10.8 MB in 3s (3,741 kB/s)\n",
            "Reading package lists... Done\n",
            "AAME.csv  sample_data  spark-3.1.1-bin-hadoop3.2  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        }
      ],
      "source": [
        "!apt-get update # Update apt-get repository.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "!pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "!ls\n",
        "\n",
        "# Initialize findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import os\n",
        "import sys\n",
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "os.environ['PYSPARK_PYTHON']=sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON']=sys.executable"
      ],
      "metadata": {
        "id": "EQ38gZGH8Vy7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('week9').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "BPB_Bd9w8XdM",
        "outputId": "6871b1ae-3688-495c-be24-fcc52865de11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7afbc37f1ae0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a512e66cb287:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>week9</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/AAME.csv'\n",
        "df=spark.read.csv(path,header=True,inferSchema=True)\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP1RPgye8Z4J",
        "outputId": "a00f9881-f54d-4b84-8e86-7363109beac4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----+----+-----+------+\n",
            "|     Date|Open|High| Low|Close|Volume|\n",
            "+---------+----+----+----+-----+------+\n",
            "|31-Dec-13|4.04|4.13|3.96| 4.09| 30735|\n",
            "|30-Dec-13|4.05|4.05|3.84|  3.9| 14646|\n",
            "|27-Dec-13|4.02|4.05|3.99| 4.05|  5047|\n",
            "|26-Dec-13|3.99|4.04|3.70| 4.01|  6309|\n",
            "|24-Dec-13|3.90|3.97|3.84| 3.95| 13592|\n",
            "+---------+----+----+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df = df.withColumn(\"Open\", col(\"Open\").cast(\"double \"))\n",
        "df = df.withColumn(\"High\", col(\"High\").cast(\"double \"))\n",
        "df = df.withColumn(\"Low\", col(\"Low\").cast(\"double \"))\n",
        "df = df.withColumn(\"Volume\", col(\"Volume\").cast(\"double \"))\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNq7_QbR8jjm",
        "outputId": "595ae0eb-0117-484e-971f-72206d1727cb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "params={}\n",
        "for col in df.columns:\n",
        "  if col!='Date':\n",
        "    mean=df.agg(f.avg(col)).collect()[0][0]\n",
        "    std=df.agg(f.stddev(col)).collect()[0][0]\n",
        "    params[col]=[mean,std]"
      ],
      "metadata": {
        "id": "jisJjiXY9PcU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key,val in params.items():\n",
        "  print(key,val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUWhrfz1-Yea",
        "outputId": "c95d3cf7-f6a4-48aa-b1d2-c9610959761a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open [2.3776905972045754, 0.8594838332913094]\n",
            "High [2.445060355781448, 0.855811640978281]\n",
            "Low [2.3282719186785252, 0.8412114675601051]\n",
            "Close [2.3474244152880743, 0.8579680474599332]\n",
            "Volume [6616.119794637764, 14076.882853421579]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "import numpy as np\n",
        "num_simulations = 1000\n",
        "\n",
        "@udf(FloatType())\n",
        "def open():\n",
        "  return np.random.normal(params['Open'][0],params['Open'][0])\n",
        "\n",
        "@udf(FloatType())\n",
        "def High():\n",
        "  return np.random.normal(params['High'][0],params['High'][0])\n",
        "\n",
        "@udf(FloatType())\n",
        "def Low():\n",
        "  return np.random.normal(params['Low'][0],params['Low'][0])\n",
        "\n",
        "@udf(FloatType())\n",
        "def Close():\n",
        "  return np.random.normal(params['Close'][0],params['Close'][0])\n",
        "\n",
        "@udf(FloatType())\n",
        "def Volume():\n",
        "  return np.random.normal(params['Volume'][0],params['Volume'][0])"
      ],
      "metadata": {
        "id": "iaJs-OCW-vP1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulated_prices_df = df.select(\n",
        "    open().alias(\"simulated_open\"),\n",
        "    Close().alias(\"simulated_close\"),\n",
        "    High().alias(\"simulated_high\"),\n",
        "    Low().alias(\"simulated_low\"),\n",
        "    Volume().alias(\"simulated_vol\")\n",
        ")\n",
        "\n",
        "# Show the results\n",
        "simulated_prices_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBEHpDc1_KHk",
        "outputId": "d7ee41fa-4faf-4abd-c74b-4252e3249b65"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------------+--------------+-------------+-------------+\n",
            "|simulated_open|simulated_close|simulated_high|simulated_low|simulated_vol|\n",
            "+--------------+---------------+--------------+-------------+-------------+\n",
            "|    -0.9782968|      -2.992069|     2.0054862|    4.8558536|    -606.2522|\n",
            "|     4.1166506|      0.7854362|   -0.14350523|     3.158376|    5753.5415|\n",
            "|    -2.4536436|      2.1556363|    0.98911667|    3.3869808|    15449.269|\n",
            "|     1.2746093|      1.1008133|     3.6142232|    1.5298885|     9710.116|\n",
            "|     3.5501034|      1.6232053|     1.4677219|   0.76851463|    7897.9414|\n",
            "|     1.5931914|     -1.4981796|     1.5963776|   -0.6019404|     8555.023|\n",
            "|     3.3889515|     -1.4126365|     1.9634925|     6.439457|     5667.803|\n",
            "|     3.5240183|       3.972301|     4.7053895|    3.7281692|    12046.267|\n",
            "|      5.535614|      2.7458217|     5.8277545|  0.029647453|    18265.121|\n",
            "|     5.9172864|    -0.70438546|     -2.440493|   -0.9055956|     9480.559|\n",
            "|     1.8193077|       3.880391|      1.428592|    5.9737425|    3017.2222|\n",
            "|     1.9383552|      1.5252535|     1.6776315|    7.4611607|    7821.6133|\n",
            "|     1.3587631|      1.2653044|     1.4731797|  -0.38975826|     6290.883|\n",
            "|     4.8451314|      4.0038357|     4.5743113|      4.77925|     5471.313|\n",
            "|     1.6839087|      3.2869675|     2.1131392|    1.8093746|    12270.243|\n",
            "|    -0.7485062|       2.854548|     3.4978294|    0.6186903|    11838.006|\n",
            "|    0.56741494|       4.180683|     0.3016394|    5.9768486|     9584.872|\n",
            "|   0.049129575|      3.1400125|     6.1462317|     6.690101|    15089.089|\n",
            "|     2.5174003|      2.7243407|     2.7761588|    3.8859942|    12729.524|\n",
            "|     3.4288354|      1.2351756|     2.7252178|   0.45246506|     -2178.59|\n",
            "+--------------+---------------+--------------+-------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}