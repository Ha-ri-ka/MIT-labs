{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Normal CNN implementation**"
      ],
      "metadata": {
        "id": "w8w9ChVlle6l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jvdy2bbleHU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CNNClassifier1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(16,32,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(32,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(batch_size,-1))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = CNNClassifier1().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
        "batch_size=50\n",
        "\n",
        "total_params = 0\n",
        "for name,param in model1.named_parameters():\n",
        "    params = param.numel()\n",
        "    total_params += params\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model1(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model1(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model1(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    print(i,predicted)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "    print(i,correct)\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ],
      "metadata": {
        "id": "gEwysNkunAbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **L2 reg, automatic and manual**"
      ],
      "metadata": {
        "id": "LoTjRTB1l_Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CNNClassifier1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(16,32,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(32,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(batch_size,-1))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = CNNClassifier1().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01,weight_decay=0.0001)\n",
        "batch_size=50\n",
        "\n",
        "total_params = 0\n",
        "for name,param in model1.named_parameters():\n",
        "    params = param.numel()\n",
        "    total_params += params\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model1(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model1(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbFuUdvLl-kC",
        "outputId": "353d202c-fe52-46ed-c347-8111bda64d93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.309\n",
            "[1,   200] loss: 2.295\n",
            "[1,   300] loss: 2.282\n",
            "[1,   400] loss: 2.263\n",
            "[1,   500] loss: 2.233\n",
            "[1,   600] loss: 2.173\n",
            "[1,   700] loss: 2.024\n",
            "[1,   800] loss: 1.665\n",
            "[1,   900] loss: 1.199\n",
            "[1,  1000] loss: 0.946\n",
            "[1,  1100] loss: 0.785\n",
            "[1,  1200] loss: 0.697\n",
            "[2,   100] loss: 0.648\n",
            "[2,   200] loss: 0.576\n",
            "[2,   300] loss: 0.526\n",
            "[2,   400] loss: 0.503\n",
            "[2,   500] loss: 0.450\n",
            "[2,   600] loss: 0.458\n",
            "[2,   700] loss: 0.424\n",
            "[2,   800] loss: 0.419\n",
            "[2,   900] loss: 0.384\n",
            "[2,  1000] loss: 0.366\n",
            "[2,  1100] loss: 0.380\n",
            "[2,  1200] loss: 0.345\n",
            "Finished Training. Final loss = 0.3894830346107483, Total params = 9594\n",
            "Correct = 9016, Total = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CNNClassifier1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(16,32,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(32,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(batch_size,-1))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = CNNClassifier1().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
        "batch_size=50\n",
        "\n",
        "total_params = 0\n",
        "for name,param in model1.named_parameters():\n",
        "    params = param.numel()\n",
        "    total_params += params\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    l2_lambda=0.0001\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model1(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        l2_reg=0\n",
        "        for param in model1.parameters():\n",
        "          l2_reg+=torch.sum((param)**2)\n",
        "        loss+=l2_lambda*l2_reg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model1(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZuOnC5NmKgy",
        "outputId": "16aa647e-6828-4dd2-8ef2-6db056a4e3bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.307\n",
            "[1,   200] loss: 2.290\n",
            "[1,   300] loss: 2.273\n",
            "[1,   400] loss: 2.247\n",
            "[1,   500] loss: 2.203\n",
            "[1,   600] loss: 2.102\n",
            "[1,   700] loss: 1.845\n",
            "[1,   800] loss: 1.403\n",
            "[1,   900] loss: 1.060\n",
            "[1,  1000] loss: 0.882\n",
            "[1,  1100] loss: 0.775\n",
            "[1,  1200] loss: 0.746\n",
            "[2,   100] loss: 0.660\n",
            "[2,   200] loss: 0.593\n",
            "[2,   300] loss: 0.590\n",
            "[2,   400] loss: 0.555\n",
            "[2,   500] loss: 0.517\n",
            "[2,   600] loss: 0.486\n",
            "[2,   700] loss: 0.451\n",
            "[2,   800] loss: 0.449\n",
            "[2,   900] loss: 0.425\n",
            "[2,  1000] loss: 0.416\n",
            "[2,  1100] loss: 0.407\n",
            "[2,  1200] loss: 0.371\n",
            "Finished Training. Final loss = 0.3301493525505066, Total params = 9594\n",
            "Correct = 8965, Total = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **L1 REG**"
      ],
      "metadata": {
        "id": "ve39aAtaoKB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CNNClassifier1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(16,32,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(32,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(batch_size,-1))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = CNNClassifier1().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01,weight_decay=0.0001)\n",
        "batch_size=50\n",
        "\n",
        "total_params = 0\n",
        "for name,param in model1.named_parameters():\n",
        "    params = param.numel()\n",
        "    total_params += params\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model1(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model1(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "kkcAhix5oIoX",
        "outputId": "8c790486-51ec-4dcb-fdab-147a87ba9de8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.319\n",
            "[1,   200] loss: 2.306\n",
            "[1,   300] loss: 2.295\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-86aa1e659e5a>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CNNClassifier1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(16,32,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(32,16,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(batch_size,-1))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = CNNClassifier1().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
        "batch_size=50\n",
        "\n",
        "total_params = 0\n",
        "for name,param in model1.named_parameters():\n",
        "    params = param.numel()\n",
        "    total_params += params\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    l1_lambda=0.0001\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model1(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        l1_reg=0\n",
        "        for param in model1.parameters():\n",
        "          l1_reg+=torch.sum(torch.abs(param))\n",
        "        loss+=l1_lambda*l1_reg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model1(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh4i-G5dn2pL",
        "outputId": "6f211f07-6879-4813-b5d0-0072fb0a77b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.339\n",
            "[1,   200] loss: 2.329\n",
            "[1,   300] loss: 2.314\n",
            "[1,   400] loss: 2.296\n",
            "[1,   500] loss: 2.255\n",
            "[1,   600] loss: 2.178\n",
            "[1,   700] loss: 2.009\n",
            "[1,   800] loss: 1.645\n",
            "[1,   900] loss: 1.211\n",
            "[1,  1000] loss: 0.990\n",
            "[1,  1100] loss: 0.839\n",
            "[1,  1200] loss: 0.766\n",
            "[2,   100] loss: 0.656\n",
            "[2,   200] loss: 0.592\n",
            "[2,   300] loss: 0.557\n",
            "[2,   400] loss: 0.513\n",
            "[2,   500] loss: 0.495\n",
            "[2,   600] loss: 0.474\n",
            "[2,   700] loss: 0.470\n",
            "[2,   800] loss: 0.433\n",
            "[2,   900] loss: 0.433\n",
            "[2,  1000] loss: 0.408\n",
            "[2,  1100] loss: 0.389\n",
            "[2,  1200] loss: 0.389\n",
            "Finished Training. Final loss = 0.34067466855049133, Total params = 9594\n",
            "Correct = 9063, Total = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dropout**"
      ],
      "metadata": {
        "id": "PehB49IQqkJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(64,128,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(128,64,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
        "                                                 nn.ReLU(),\n",
        "                                                 nn.Dropout(0.5),\n",
        "                                                 nn.Linear(20,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(batch_size,-1))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNClassifier().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "batch_size=50\n",
        "\n",
        "total_params = 0\n",
        "for name,param in model.named_parameters():\n",
        "    params = param.numel()\n",
        "    total_params += params\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0weG2b-qhZ8",
        "outputId": "725d6509-7780-4a3d-f505-42b258d6c205"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.311\n",
            "[1,   200] loss: 2.304\n",
            "[1,   300] loss: 2.294\n",
            "[1,   400] loss: 2.279\n",
            "[1,   500] loss: 2.263\n",
            "[1,   600] loss: 2.236\n",
            "[1,   700] loss: 2.182\n",
            "[1,   800] loss: 2.092\n",
            "[1,   900] loss: 1.938\n",
            "[1,  1000] loss: 1.755\n",
            "[1,  1100] loss: 1.587\n",
            "[1,  1200] loss: 1.437\n",
            "[2,   100] loss: 1.329\n",
            "[2,   200] loss: 1.237\n",
            "[2,   300] loss: 1.153\n",
            "[2,   400] loss: 1.108\n",
            "[2,   500] loss: 1.031\n",
            "[2,   600] loss: 1.025\n",
            "[2,   700] loss: 0.962\n",
            "[2,   800] loss: 0.921\n",
            "[2,   900] loss: 0.851\n",
            "[2,  1000] loss: 0.839\n",
            "[2,  1100] loss: 0.816\n",
            "[2,  1200] loss: 0.818\n",
            "Finished Training. Final loss = 1.0120898485183716, Total params = 149798\n",
            "Correct = 7430, Total = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Early Stopping**"
      ],
      "metadata": {
        "id": "FzVVPBQJtG6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(64,128,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                 nn.Conv2d(128,64,3),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d((2,2),stride=2),\n",
        "                                )\n",
        "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
        "                                                 nn.ReLU(),\n",
        "                                                 nn.Linear(20,10,bias=True),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.net(x)\n",
        "        return self.classification_head(features.view(-1, 64))\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root=\"./data\", download=True, train=True, transform=ToTensor())\n",
        "train_loader = DataLoader(mnist_trainset, batch_size=50, shuffle=True)\n",
        "mnist_testset = datasets.MNIST(root=\"./data\", download=True, train=False, transform=ToTensor())\n",
        "test_loader = DataLoader(mnist_testset, batch_size=50, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNClassifier().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "batch_size = 50\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('Total number of learnable parameters:', total_params)\n",
        "\n",
        "patience = 5\n",
        "best_validation_loss = float('inf')\n",
        "current_patience = 0\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        validation_loss = 0.0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "        validation_loss /= len(test_loader)\n",
        "\n",
        "        # Check for improvement in validation loss\n",
        "        if validation_loss < best_validation_loss:\n",
        "            best_validation_loss = validation_loss\n",
        "            current_patience = 0\n",
        "            # Save the model if desired\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            current_patience += 1\n",
        "            # Check if early stopping criteria are met\n",
        "            if current_patience > patience:\n",
        "                print(\"Early stopping! No improvement for {} epochs.\".format(patience))\n",
        "                break\n",
        "\n",
        "print(f\"Finished Training. Best validation loss = {best_validation_loss:.3f}, Total params = {total_params}\")\n",
        "\n",
        "correct,total = 0,0\n",
        "for i,vdata in enumerate(test_loader):\n",
        "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
        "    toutputs = model(tinputs)\n",
        "\n",
        "    _,predicted = torch.max(toutputs,1)\n",
        "    total += tlabels.size(0)\n",
        "    correct += (predicted==tlabels).sum()\n",
        "\n",
        "print(f\"Correct = {correct}, Total = {total}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNdJqNMbtLGi",
        "outputId": "b1ac641e-aa7c-4d4f-babf-5183813bf4eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of learnable parameters: 149798\n",
            "[1,   100] loss: 2.305\n",
            "[1,   200] loss: 2.292\n",
            "[1,   300] loss: 2.276\n",
            "[1,   400] loss: 2.254\n",
            "[1,   500] loss: 2.214\n",
            "[1,   600] loss: 2.121\n",
            "[1,   700] loss: 1.932\n",
            "[1,   800] loss: 1.597\n",
            "[1,   900] loss: 1.235\n",
            "[1,  1000] loss: 0.973\n",
            "[1,  1100] loss: 0.789\n",
            "[1,  1200] loss: 0.663\n",
            "[2,   100] loss: 0.577\n",
            "[2,   200] loss: 0.501\n",
            "[2,   300] loss: 0.475\n",
            "[2,   400] loss: 0.423\n",
            "[2,   500] loss: 0.385\n",
            "[2,   600] loss: 0.344\n",
            "[2,   700] loss: 0.330\n",
            "[2,   800] loss: 0.340\n",
            "[2,   900] loss: 0.313\n",
            "[2,  1000] loss: 0.289\n",
            "[2,  1100] loss: 0.283\n",
            "[2,  1200] loss: 0.296\n",
            "Finished Training. Best validation loss = 0.243, Total params = 149798\n",
            "Correct = 9281, Total = 10000\n"
          ]
        }
      ]
    }
  ]
}