{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement convolution operation for a sample image of shape (H=6, W=6, C=1) with a random kernel of size (3,3) using torch.nn.functional.conv2d.What is the dimension of the output image? Apply, various values for parameter stride=1 and note the change in the dimension of the output image. Arrive at an equation for the output image size with respect to the kernel size and stride and verify your answer with code. Now, repeat the exercise by changing padding parameter. Obtain a formula using kernel, stride, and padding to get the output image size. What is the total number of parameters in your network? Verify with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=torch.rand(6,6)\n",
    "image=image.unsqueeze(dim=0)\n",
    "image=image.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=torch.ones(3,3)\n",
    "kernel=kernel.unsqueeze(0)\n",
    "kernel=kernel.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(stride,padding):\n",
    "    print(f\"--------------stride={stride} padding={padding}--------------------\")\n",
    "    output=F.conv2d(image,kernel, stride=stride, padding=padding)\n",
    "    if(stride==1 and padding==0):\n",
    "        print(f\"output={output}\")\n",
    "    print(f\"shape of output={output.shape} \",end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------stride=1 padding=0--------------------\n",
      "output=tensor([[[[3.5465, 3.0820, 2.6857, 3.1748],\n",
      "          [2.7923, 2.0472, 2.4185, 2.7626],\n",
      "          [2.7472, 2.4085, 1.8330, 2.6088],\n",
      "          [4.4014, 4.6657, 3.7413, 3.6688]]]])\n",
      "shape of output=torch.Size([1, 1, 4, 4]) \n",
      "\n",
      "--------------stride=1 padding=1--------------------\n",
      "shape of output=torch.Size([1, 1, 6, 6]) \n",
      "\n",
      "--------------stride=2 padding=2--------------------\n",
      "shape of output=torch.Size([1, 1, 4, 4]) \n",
      "\n",
      "--------------stride=3 padding=3--------------------\n",
      "shape of output=torch.Size([1, 1, 4, 4]) \n",
      "\n",
      "--------------stride=4 padding=4--------------------\n",
      "shape of output=torch.Size([1, 1, 3, 3]) \n",
      "\n",
      "--------------stride=5 padding=5--------------------\n",
      "shape of output=torch.Size([1, 1, 3, 3]) \n",
      "\n",
      "--------------stride=6 padding=6--------------------\n",
      "shape of output=torch.Size([1, 1, 3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stride=[0,1,2,3,4,5,6]\n",
    "padding=[0,1,2,3,4,5,6]\n",
    "for s,p in zip(stride,padding):\n",
    "    if(s==0): s=1\n",
    "    convolution(s,p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
